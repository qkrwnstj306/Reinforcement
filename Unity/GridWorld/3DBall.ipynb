{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Ball 예제를 Unity API를 통해 직접 python으로 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b983a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed40aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "-- 환경 빌드 방법 --\n",
    "\n",
    "* 환경 빌드란?\n",
    "해당 유니티 프로젝트를, 설정한 운영체제에 맞는 실행 파일로 만드는 것\n",
    "\n",
    "File -> Build -> Settings\n",
    "\n",
    "Add Open Scenes (현재 씬을 추가)\n",
    "\n",
    "플랫폼 설정 (Windows, Mac, Linux)\n",
    "\n",
    "Player Settings -> Product Name(빌드하고자 하는 이름) & Resolution(실행될 창의 크기)\n",
    "\n",
    "Build!\n",
    "\n",
    "-- Each Component --\n",
    "* behavior : 같은 brain을 공유하는 에이전트들의 그룹(behavior parameters를 동일하게 사용) \n",
    "\n",
    "* env.get_steps : decision_stpes, terminal_steps를 return | 각 step에서 에이전트의 상태, 행동, 보상 등의 정보를 반환한다. \n",
    "                 아직 환경의 에피소드가 끝나지 않은 상태라면 정보는 decision_stpes에 저장, 마지막 step이면 terminal_steps에 저장되고 \n",
    "                 decision_steps에는 다음 에피소드의 첫 스텝 정보가 저장된다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041485b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "name of behavior: 3DBall?team=0\n",
      "total reward for ep 0 is 0.5000000223517418\n",
      "total reward for ep 1 is 0.8000000268220901\n",
      "total reward for ep 2 is 1.3000000342726707\n",
      "total reward for ep 3 is 0.700000025331974\n",
      "total reward for ep 4 is 2.1000000461935997\n"
     ]
    },
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityCommunicatorStoppedException\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m env\u001b[38;5;241m.\u001b[39mset_actions(behavior_name, action)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#실제 액션 수행\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#스텝 종료 후 에이전트의 정보(보상, 상태 등) 취득\u001b[39;00m\n\u001b[1;32m     40\u001b[0m decision_steps, terminal_steps \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_steps(behavior_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/mlagents_envs/timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/mlagents_envs/environment.py:350\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicator\u001b[38;5;241m.\u001b[39mexchange(step_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_process)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator has exited.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_behavior_specs(outputs)\n\u001b[1;32m    352\u001b[0m rl_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mrl_output\n",
      "\u001b[0;31mUnityCommunicatorStoppedException\u001b[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #환경을 정의, 빌드한 프로젝트에 대해서 경로 설정\n",
    "    #\"Couldn't start socket communication\" 이라는 error가 뜨면 worker_id를 바꿔준다.\n",
    "    env = UnityEnvironment(file_name='/home/qkrwnstj/ml-agents/Project/3DBall.x86_64', worker_id = 2)\n",
    "    \n",
    "    #behavior 불러오기\n",
    "    env.reset()\n",
    "    behavior_name = list(env.behavior_specs.keys())[0] \n",
    "    print(f'name of behavior: {behavior_name}') # 3DBall?team=0\n",
    "    spec = env.behavior_specs[behavior_name]\n",
    "    \n",
    "    #에피소드 진행을 위한 반복문(10 에피소드 반복)\n",
    "    for ep in range(10):\n",
    "        #환경 초기화\n",
    "        env.reset()\n",
    "\n",
    "        #에이전트가 행동을 요청한 상태인지, 마지막 상태인지 확인\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "       \n",
    "        #한 에이전트를 기준으로 로그를 출력\n",
    "        tracked_agent = -1\n",
    "        done = False\n",
    "        ep_rewards =0 \n",
    "        \n",
    "        while not done:\n",
    "        #tracked agent 지정\n",
    "            if tracked_agent == -1 and len(decision_steps) >= 1 :\n",
    "                tracked_agent = decision_steps.agent_id[0] # 0 (index)\n",
    "                \n",
    "            #랜덤 액션 결정, 12개의 agent에 대한 행동을 모두 도출\n",
    "            action = spec.action_spec.random_action(len(decision_steps))\n",
    "\n",
    "            #set actions, 12개의 에이전트가 모두 동일한 behavior parameter를 가지기 때문에 하나의 behavior_name에 대해서 행동을 결정\n",
    "            env.set_actions(behavior_name, action)\n",
    "\n",
    "            #실제 액션 수행\n",
    "            env.step()\n",
    "\n",
    "            #스텝 종료 후 에이전트의 정보(보상, 상태 등) 취득\n",
    "            decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "\n",
    "            #추적중인 에이전트가 행동이 가능한 상태와 종료 상태일 때를 구분하여 보상 저장\n",
    "            if tracked_agent in decision_steps:\n",
    "                ep_rewards += decision_steps[tracked_agent].reward\n",
    "            if tracked_agent in terminal_steps:\n",
    "                ep_rewards += terminal_steps[tracked_agent].reward\n",
    "                done = True\n",
    "    \n",
    "        #한 에피소드가 종료되고 추적중인 에이전트에 대해서 해당 에피소드에서의 보상 출력\n",
    "        print(f'total reward for ep {ep} is {ep_rewards}')\n",
    "    \n",
    "    #환경 종료\n",
    "    env.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639a092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
