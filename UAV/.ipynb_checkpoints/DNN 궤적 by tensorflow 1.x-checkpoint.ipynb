{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf #2차원\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "import random as rd\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "K=int(4)\n",
    "deltat=0.5 #1\n",
    "T=20 #100\n",
    "delta=deltat*(K+1)\n",
    "N=int(T/deltat)\n",
    "pmax=40*deltat\n",
    "pavg=10*deltat \n",
    "beta=1\n",
    "zeta=1\n",
    "noisea=10**(-8)\n",
    "noise=10**(-8)\n",
    "V=5\n",
    "H=5\n",
    "L=V*deltat\n",
    "\n",
    "inputs=9\n",
    "output=(3+K)*N #\n",
    "node_num = output*2  \n",
    "hidden_nodesL2=node_num     \n",
    "hidden_nodesL3=node_num\n",
    "hidden_nodesL4=node_num    \n",
    "hidden_nodesL5=node_num    \n",
    "hidden_nodesL6=node_num    \n",
    "\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None,inputs])\n",
    "# hidden layer의 node수를 output의 2배 이상\n",
    "W1=tf.get_variable(\"W1\",shape=[inputs,hidden_nodesL2],initializer=tf.keras.initializers.he_normal())\n",
    "b1=tf.get_variable(\"b1\",shape=[hidden_nodesL2],initializer=tf.keras.initializers.he_normal())\n",
    "L1=tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "L1 = tf.nn.experimental.stateless_dropout(L1, rate=0.1, seed=[1, 0])\n",
    "\n",
    "W2=tf.get_variable(\"W2\",shape=[hidden_nodesL2,hidden_nodesL3],initializer=tf.keras.initializers.he_normal())\n",
    "b2=tf.get_variable(\"b2\",shape=[hidden_nodesL3],initializer=tf.keras.initializers.he_normal())\n",
    "L2=tf.nn.relu(tf.matmul(L1,W2)+b2)\n",
    "L2 = tf.nn.experimental.stateless_dropout(L2, rate=0.1, seed=[1, 0])\n",
    "\n",
    "W3=tf.get_variable(\"W3\",shape=[hidden_nodesL3,hidden_nodesL4],initializer=tf.keras.initializers.he_normal())\n",
    "b3=tf.get_variable(\"b3\",shape=[hidden_nodesL4],initializer=tf.keras.initializers.he_normal())\n",
    "L3=tf.nn.relu(tf.matmul(L2,W3)+b3)\n",
    "L3 = tf.nn.experimental.stateless_dropout(L3, rate=0.1, seed=[1, 0])\n",
    "\n",
    "W4=tf.get_variable(\"W4\",shape=[hidden_nodesL4,hidden_nodesL5],initializer=tf.keras.initializers.he_normal())\n",
    "b4=tf.get_variable(\"b4\",shape=[hidden_nodesL5],initializer=tf.keras.initializers.he_normal())\n",
    "L4=tf.nn.relu(tf.matmul(L3,W4)+b4)\n",
    "L4 = tf.nn.experimental.stateless_dropout(L4, rate=0.1, seed=[1, 0])\n",
    "\n",
    "W5=tf.get_variable(\"W5\",shape=[hidden_nodesL5,hidden_nodesL6],initializer=tf.keras.initializers.he_normal())\n",
    "b5=tf.get_variable(\"b5\",shape=[hidden_nodesL6],initializer=tf.keras.initializers.he_normal())\n",
    "L5=tf.nn.relu(tf.matmul(L4,W5)+b5)\n",
    "L5 = tf.nn.experimental.stateless_dropout(L5, rate=0.1, seed=[1, 0])\n",
    "\n",
    "W6=tf.get_variable(\"W6\",shape=[hidden_nodesL6,output],initializer=tf.keras.initializers.he_normal())\n",
    "b6=tf.get_variable(\"b6\",shape=[output],initializer=tf.keras.initializers.he_normal())\n",
    "Loutput=tf.nn.sigmoid(tf.matmul(L5,W6)+b6)\n",
    "# batch X (K+3)N\n",
    "\n",
    "# Loutput - > 1batch X (K+3)N\n",
    "bch_size=tf.shape(Loutput)[0]\n",
    "\n",
    "tmp_P=Loutput[:,:N]#N개\n",
    "tmp_a=Loutput[:,N:(K+1)*N]#KN개\n",
    "tmp_qx=Loutput[:,(K+1)*N:(K+2)*N]#N개\n",
    "tmp_qy=Loutput[:,(K+2)*N:(K+3)*N]#N개\n",
    "\n",
    "P=tf.reshape(pmax*tmp_P,[bch_size,N]) #정규화된 output을 다시 원래 크기로\n",
    "alpha=tf.reshape(tmp_a,[bch_size,K*N])\n",
    "qx=tf.reshape(20*tmp_qx,[bch_size,N])\n",
    "qy=tf.reshape(10*tmp_qy,[bch_size,N])\n",
    "\n",
    "nodex=tf.reshape(X[:,:4]*20,[bch_size,4]) # input\n",
    "nodey=tf.reshape(X[:,4:8]*10,[bch_size,4])\n",
    "Rmin=tf.reshape(X[:,8:9]*15,[bch_size,1]) \n",
    "\n",
    "nodex1 = tf.reshape(nodex[:,0],[bch_size,1]) #user node W를 늘리기\n",
    "nodex11 = tf.reshape(nodex[:,0],[bch_size,1])\n",
    "nodex2 = tf.reshape(nodex[:,1],[bch_size,1])\n",
    "nodex22 = tf.reshape(nodex[:,1],[bch_size,1])\n",
    "nodex3 = tf.reshape(nodex[:,2],[bch_size,1])\n",
    "nodex33 = tf.reshape(nodex[:,2],[bch_size,1])\n",
    "nodex4 = tf.reshape(nodex[:,3],[bch_size,1])\n",
    "nodex44 = tf.reshape(nodex[:,3],[bch_size,1])\n",
    "\n",
    "nodey1 = tf.reshape(nodey[:,0],[bch_size,1])\n",
    "nodey11 = tf.reshape(nodey[:,0],[bch_size,1])\n",
    "nodey2 = tf.reshape(nodey[:,1],[bch_size,1])\n",
    "nodey22 = tf.reshape(nodey[:,1],[bch_size,1])\n",
    "nodey3 = tf.reshape(nodey[:,2],[bch_size,1])\n",
    "nodey33 = tf.reshape(nodey[:,2],[bch_size,1])\n",
    "nodey4 = tf.reshape(nodey[:,3],[bch_size,1])\n",
    "nodey44 = tf.reshape(nodey[:,3],[bch_size,1])\n",
    "\n",
    "for j in range(N-1):\n",
    "  nodex11 = tf.concat([nodex11,nodex1],axis=1) # batch x N\n",
    "  nodex22 = tf.concat([nodex22,nodex2],axis=1)\n",
    "  nodex33 = tf.concat([nodex33,nodex3],axis=1)\n",
    "  nodex44 = tf.concat([nodex44,nodex4],axis=1)\n",
    "  nodey11 = tf.concat([nodey11,nodey1],axis=1)\n",
    "  nodey22 = tf.concat([nodey22,nodey2],axis=1)\n",
    "  nodey33 = tf.concat([nodey33,nodey3],axis=1)\n",
    "  nodey44 = tf.concat([nodey44,nodey4],axis=1)\n",
    "\n",
    "h1=beta/(tf.add(tf.pow(tf.subtract(qx,nodex11),2),tf.pow(tf.subtract(qy,nodey11),2))+H**2) # batch x N\n",
    "h2=beta/(tf.add(tf.pow(tf.subtract(qx,nodex22),2),tf.pow(tf.subtract(qy,nodey22),2))+H**2)\n",
    "h3=beta/(tf.add(tf.pow(tf.subtract(qx,nodex33),2),tf.pow(tf.subtract(qy,nodey33),2))+H**2)\n",
    "h4=beta/(tf.add(tf.pow(tf.subtract(qx,nodex44),2),tf.pow(tf.subtract(qy,nodey44),2))+H**2)\n",
    "\n",
    "#H=tf.concat([h1,h2,h3,h4],0) \n",
    "\n",
    "a=tf.zeros([bch_size,1])\n",
    "qxx=tf.concat([a,qx],1) # |q[N+1]-q[0]| =0     batch x (N+1)\n",
    "qyy=tf.concat([a,qy],1)\n",
    "\n",
    "#constraint (11) -> 모든 N을 더한 downlink rate가 모든 k에 대해서 만족해야 된다.\n",
    "RD1=tf.log(1+tf.divide(tf.multiply(tf.multiply((1-alpha[:,:N]),h1),P),((1-alpha[:,:N])*noisea+noise)))/np.log(2) # 100 X 1 X 20\n",
    "RD2=tf.log(1+tf.divide(tf.multiply(tf.multiply((1-alpha[:,N:2*N]),h2),P),((1-alpha[:,N:2*N])*noisea+noise)))/np.log(2)\n",
    "RD3=tf.log(1+tf.divide(tf.multiply(tf.multiply((1-alpha[:,2*N:3*N]),h3),P),((1-alpha[:,2*N:3*N])*noisea+noise)))/np.log(2)\n",
    "RD4=tf.log(1+tf.divide(tf.multiply(tf.multiply((1-alpha[:,3*N:4*N]),h4),P),((1-alpha[:,3*N:4*N])*noisea+noise)))/np.log(2)\n",
    "RD1m=tf.reduce_mean(tf.subtract(Rmin,tf.math.reduce_mean(RD1,axis = 1 , keep_dims=True)),0) # 100 X 1 로 일단 계산\n",
    "RD2m=tf.reduce_mean(tf.subtract(Rmin,tf.reduce_mean(RD2,axis = 1 , keep_dims=True)),0) \n",
    "RD3m=tf.reduce_mean(tf.subtract(Rmin,tf.reduce_mean(RD3,axis = 1 , keep_dims=True)),0) \n",
    "RD4m=tf.reduce_mean(tf.subtract(Rmin,tf.reduce_mean(RD4,axis = 1 , keep_dims=True)),0) \n",
    "RD1_real = tf.maximum(RD1m,0) # batch를 평균 내기  scalar\n",
    "RD2_real = tf.maximum(RD2m,0)\n",
    "RD3_real = tf.maximum(RD3m,0)\n",
    "RD4_real = tf.maximum(RD4m,0) \n",
    "\n",
    "#min RU 고르기\n",
    "E1=tf.multiply(tf.multiply(h1,alpha[:,:N]),P)*deltat # batch x N\n",
    "E2=tf.multiply(tf.multiply(h2,alpha[:,N:2*N]),P)*deltat\n",
    "E3=tf.multiply(tf.multiply(h3,alpha[:,2*N:3*N]),P)*deltat\n",
    "E4=tf.multiply(tf.multiply(h4,alpha[:,3*N:4*N]),P)*deltat\n",
    "RU1=tf.reduce_mean(tf.log(1+tf.multiply(h1,E1)/((noisea+noise)*deltat))/np.log(2)) \n",
    "RU2=tf.reduce_mean(tf.log(1+tf.multiply(h2,E2)/((noisea+noise)*deltat))/np.log(2))\n",
    "RU3=tf.reduce_mean(tf.log(1+tf.multiply(h3,E3)/((noisea+noise)*deltat))/np.log(2))\n",
    "RU4=tf.reduce_mean(tf.log(1+tf.multiply(h4,E4)/((noisea+noise)*deltat))/np.log(2))\n",
    "\n",
    "a_1=tf.minimum(RU1,RU2)\n",
    "b=tf.minimum(a_1,RU3)\n",
    "c=tf.minimum(b,RU4)\n",
    "RUmin = c\n",
    "\n",
    "qx_init = tf.reduce_mean(qx[:,0:1])\n",
    "qx_finish = tf.reduce_mean(qx[:,N-1:N])\n",
    "qy_init = tf.reduce_mean(qy[:,0:1])\n",
    "qy_finish = tf.reduce_mean(qy[:,N-1:N])\n",
    "# constraint (2)\n",
    "P_sub1=tf.reduce_mean(P,axis = 1 , keep_dims=True)-pavg\n",
    "P_sub2=tf.reduce_mean(P-pmax)\n",
    "\n",
    "C1= tf.reduce_mean(tf.maximum(tf.sqrt(tf.add(tf.pow(tf.subtract(qx[:,1:N],qxx[:,1:N]),2),\\\n",
    "                                             tf.pow(tf.subtract(qy[:,1:N],qyy[:,1:N]),2)))-L,0))\n",
    "c1_con =tf.reduce_mean((tf.sqrt(tf.add(tf.pow(tf.subtract(qx[:,1:N],qxx[:,1:N]),2),\\\n",
    "                                             tf.pow(tf.subtract(qy[:,1:N],qyy[:,1:N]),2)))-L))\n",
    "C2=tf.maximum(tf.reduce_mean(P_sub1),0) #constraint (4)\n",
    "c2_con =tf.reduce_mean(P_sub1)\n",
    "C3=tf.maximum(tf.reduce_mean(P_sub2),0) #constraint (5)\n",
    "c3_con =tf.reduce_mean(P_sub2)\n",
    "C4=(RD1_real+RD2_real+RD3_real+RD4_real) # 이미 max는 적용돼있다. constraint (11)\n",
    "c4_con = RD1m+RD2m+RD3m+RD4m\n",
    "C5=tf.maximum(tf.abs(tf.subtract(qx_init,qx_finish))+tf.abs(tf.subtract(qy_init,qy_finish)),0)  # constraint (3)\n",
    "c5_con1 = (tf.abs(tf.subtract(qx_init,qx_finish))+tf.abs(tf.subtract(qy_init,qy_finish)))\n",
    "#Reward=-RUmin+C1+C2+C3+C4+C5\n",
    "Reward=-tf.exp(RUmin)+(C1*50+C2*10000+C3+C5+C4)*35000 #기하평균? 벌점을 줄이면 rate는 높아진다?\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.001).minimize(Reward) #0.001 -> 0.01\n",
    "\n",
    "batch_size=512 #512\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "print(tf.config.list_physical_devices('GPU')) # TensorFlow가 GPU를 사용하고 있는지 확인\n",
    "with tf.device('/cpu:0'):\n",
    "  print(tf.config.list_physical_devices('GPU')) # TensorFlow가 GPU를 사용하고 있는지 확인\n",
    "  for cnt in range(10000):#300 # 이거 안되면 초기 궤적 집어넣기,  (현재 GPU + batch size 100 + dropout + learning rate 0.01은 하면 안됨..)\n",
    "    hh=[] \n",
    "    for j in range(batch_size): #batch 만큼 sample 생성\n",
    "        x=[0 for i in range(9)] # sample 생성   \n",
    "        for i in range(inputs):\n",
    "            if i<4:\n",
    "                x[i]=float(rd.randint(0,20))/20\n",
    "            elif i<8:\n",
    "                x[i]=float(rd.randint(0,10))/10\n",
    "            elif i ==8:\n",
    "                x[i]=15.0/15#float(rd.randint(5,15)) #/15\n",
    "            '''elif i<=29 : # 9 ~ 28 \n",
    "                x[i] = 10*np.cos(2*np.pi*(i-10)/N)+10\n",
    "            else : # 29 ~ 48\n",
    "                x[i] = 5*np.sin(2*np.pi*(i-30)/N)+5'''\n",
    "        hh.append(x)\n",
    "        if cnt == 5000 and j==2:\n",
    "          Htest = x\n",
    "    hh = np.array(hh)\n",
    "    hh = np.reshape(hh,(batch_size, inputs))\n",
    "    \n",
    "    for epoch in range(1):#1500\n",
    "      with tf.device('/device:GPU:0'):\n",
    "        c1_1,c2_1,c3_1,c4_1,rate,reward,_=sess.run([c1_con,c2_con,c3_con,c4_con,RUmin,Reward,optimizer],feed_dict={X:hh})\n",
    "        \n",
    "    #f tf.mod(cnt,1000)==0:\n",
    "    print(\"Loop\",cnt,'Reward',reward,'rate',rate)\n",
    "    print(\"c1\",c1_1,\"c2\",c2_1,\"c3\",c3_1,\"c4\",c4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [0,10/20,20/20,10/20,5/10,0,5/10,10/10,15/15] #/20/10/15\n",
    "'''for i in range(9,49):\n",
    "    if i<=29 : # 10 ~ 29 \n",
    "        test_input.append(10*np.cos(2*np.pi*(i-10)/N)+10)\n",
    "    else : # 30 ~ 49\n",
    "        test_input.append(5*np.sin(2*np.pi*(i-30)/N)+5)'''\n",
    "test_input = np.reshape(test_input,(1, 9))\n",
    "#Htest = np.reshape(Htest,(1,9))\n",
    "with tf.device('/cpu:0'):\n",
    "  for i in range(10000):\n",
    "    alphaa,c1,c2,c3,c4,ru1,ru2,ru3,ru4,test_rate,test_reward,test_qx,test_qy,test_p,_\\\n",
    "    =sess.run([alpha,c1_con,c2_con,c3_con,c4_con,RU1,RU2,RU3,RU4,RUmin,Reward,qx,qy,P,optimizer],\\\n",
    "              feed_dict={X:test_input})#rate, 벌점을 준 rate, qx, qy, p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_p)\n",
    "print(c1,c2,c3,c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_rate)\n",
    "#print(list(test_p))\n",
    "###print(list(alpha))\n",
    "print(list(test_qx))\n",
    "print(list(test_qy))\n",
    "#print(len(test_qx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182985da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_qx = list(test_qx)[0]\n",
    "test_qy = list(test_qy)[0]\n",
    "plt.xlim(0,20)\n",
    "plt.ylim(0,10)\n",
    "plt.plot(test_qx,test_qy)\n",
    "#plt.scatter(test_qx,test_qy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af93a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29e862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60eaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d57325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba51fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617dd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
