{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c985946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import collections # collections 모듈에 있는 deque를 사용하기 위함\n",
    "#dequq는 double-ended queue로써, queue와 stack의 기능을 다 쓸 수 있다.\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5da451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enva():\n",
    "    def __init__(self):\n",
    "        self.height = 10\n",
    "        self.width = 10\n",
    "        self.num_obstacle_range =5\n",
    "        self.num_obstacle_range_min = 3\n",
    "        self.turn = 0\n",
    "        self.position = int(round(self.width/2))\n",
    "        self.map = np.array([[0.0 for j in range(self.width)] for i in range(self.height)])\n",
    "        self.map[self.height-1][self.position] = 2.\n",
    "        self.done = False\n",
    "        \n",
    "    def step(self, key):\n",
    "        #obstacle down\n",
    "        i = self.height - 2\n",
    "        while(i>=0):\n",
    "            self.map[i+1] = self.map[i]\n",
    "            i -= 1\n",
    "        #obstacle init(first_line)\n",
    "        self.map[0] = np.array([0 for j in range(self.width)])\n",
    "        #obstacle making\n",
    "        num_obstacle = random.randrange(self.num_obstacle_range_min,self.num_obstacle_range)\n",
    "        i = 0\n",
    "        while(i < num_obstacle):\n",
    "            position_obstacle = random.randrange(0,self.width)\n",
    "            if (self.map[0][position_obstacle] == 1.0):\n",
    "                continue\n",
    "            self.map[0][position_obstacle] = 1.0\n",
    "            i += 1\n",
    "        #big_obstacle\n",
    "        big_obstacle = random.randrange(0,20)\n",
    "        if(big_obstacle == -1): ############### 1로 바꾸면 큰 똥이 생긴다.\n",
    "            big_obstacle = random.randrange(1,self.width-1)\n",
    "            for j in range(3):\n",
    "                for k in range(-1,2):\n",
    "                    self.map[j][big_obstacle + k] = 1.\n",
    "        #player position\n",
    "        reward = 1\n",
    "        # 0 : 왼쪽, 1 : 가만히, 2 : 오른쪽\n",
    "        if key == 0:\n",
    "            if(self.position>0):\n",
    "                self.position -= 1\n",
    "            \n",
    "        if key == 1:\n",
    "            pass      \n",
    "        if key == 2:\n",
    "            if(self.position<self.width-1):\n",
    "                self.position += 1\n",
    "                  \n",
    "        if (self.map[self.height-1][self.position] == 1.0):\n",
    "                    reward = 0\n",
    "                    self.done = True\n",
    "                    #print(\"====Game Over====\")\n",
    "                        \n",
    "        self.map[self.height-1][self.position] = 2.0\n",
    "        #reward(turn(time))\n",
    "        self.turn += 1\n",
    "        \n",
    "        return torch.flatten(torch.tensor(self.map),0), reward, self.done, _ \n",
    "\n",
    "    def reset(self):\n",
    "        self.turn = 0\n",
    "        self.position = round(self.width/2)\n",
    "        self.map = np.array([[0.0 for j in range(self.width)] for i in range(self.height)])\n",
    "        self.map[self.height-1][self.position] = 2.0\n",
    "        self.done = False\n",
    "        \n",
    "        return torch.flatten(torch.tensor(self.map),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbc2581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nerual network setting -> good performance\n",
    "#hyperparameters\n",
    "buffer_size =30000   # environment's size에 맞춰서 setting\n",
    "batch_size = 32   \n",
    "gamma = 0.98  # Large future weight\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Agent,self).__init__()\n",
    "        self.fc1 = nn.Linear(100,128)\n",
    "        self.fc2 = nn.Linear(128,128)\n",
    "        self.fc3 = nn.Linear(128,128)\n",
    "        self.fc4 = nn.Linear(128,3)  # 좌우, 제자리\n",
    "  \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "  \n",
    "  \n",
    "    def select_action(self,state,eps):   # state, reward를 받으면 action이 나오는 relation. \n",
    "                                        # but reward는 memory를 통해 사용하므로 state를 받아서 action을 뽑는다.\n",
    "\n",
    "        coin = random.random() # 0~1\n",
    "        out_value = self.forward(state) # \n",
    "        if coin < eps:   # random action\n",
    "            a = random.randint(0,2) # 0 ,1 ,2 choice\n",
    "        else : # optimize action\n",
    "            a = torch.argmax(out_value).item() # a는 tensor가 아닌 int로 들어가야 한다.\n",
    "                                               # 둘 중 높은 value를 가진 index가 action이다. \n",
    "        return a\n",
    "\n",
    "class replay_buffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen = buffer_size)\n",
    "    def put(self,input): # buffer에 store\n",
    "        self.buffer.append(input) # dtype = tensor  4개가 한 묶음으로 들어가야됨\n",
    "\n",
    "    def sampling(self,bat_ch): \n",
    "        mini_batch = random.sample(self.buffer,bat_ch) # bat_ch X 4 (list), dtype = tensor\n",
    "                                                       # buffer에서 batch_size (현재 32)만큼 sampling을 한다.\n",
    "        #s_list, a_list, r_prime_list, s_prime_list,done_mask_lst = [],[],[],[],[] # list로 각각을 저장할거임\n",
    "        a_list, r_prime_list, done_mask_lst = [],[],[]\n",
    "        s_list = torch.tensor([0 for i in range(100)],dtype = torch.float).unsqueeze(dim=0)\n",
    "        s_prime_list = torch.tensor([0 for i in range(100)],dtype = torch.float).unsqueeze(dim=0)\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "              s, a, r_prime, s_prime,done_mask = transition\n",
    "              \n",
    "              \n",
    "              # a : int, r_prime : float\n",
    "              s_list = torch.cat([s_list,s.unsqueeze(dim=0)],dim=0) \n",
    "              s_prime_list = torch.cat([s_prime_list,s_prime.unsqueeze(dim=0)],dim=0)         \n",
    "              #s_list.append(s)\n",
    "              a_list.append([a]) # 열로 쌓는다\n",
    "              r_prime_list.append([r_prime])\n",
    "              #s_prime_list.append(s_prime)\n",
    "              done_mask_lst.append([done_mask])\n",
    "        s_list = s_list[1:,:]\n",
    "        s_prime_list = s_prime_list[1:,:]      \n",
    "        return torch.tensor(s_list, dtype=torch.float), torch.tensor(a_list), \\\n",
    "                       torch.tensor(r_prime_list), torch.tensor(s_prime_list, dtype=torch.float),torch.tensor(done_mask_lst)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "def train(q,q_target,disk,optimizer):\n",
    "    for i in range(10):\n",
    "        s, a, r, s_prime,done_mask = disk.sampling(batch_size) # s : batch_size x 4    \n",
    "\n",
    "        q_out = q(s) # batch_size x 4 \n",
    "        q_a = q_out.gather(1,a) # dim =1에서 index가 a인 것들로 재구성\n",
    "        #print(q_a.shape)  # batch_size x 1\n",
    "        qtarget_out = q_target(s_prime) # s'에서의 value가 4개 나옴 -> batch_size x 4\n",
    "        #print(qtarget_out.max(1)) 값 반환 하는데, 이 값은 행벡터\n",
    "        max_q_prime = qtarget_out.max(1)[0].unsqueeze(1) # dim = 1 에서 max값 가지고 온다. batch_size x 1로 만듦\n",
    "\n",
    "        target = r + max_q_prime*gamma* done_mask \n",
    "        loss = F.smooth_l1_loss(q_a,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50c6ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score :  9\n",
      "best score :  11\n",
      "best score :  12\n",
      "best score :  13\n",
      "best score :  16\n",
      "best score :  20\n",
      "best score :  22\n",
      "n_episode :100, score : 10.7, n_buffer : 1169,eps = 0.075\n",
      "n_episode :200, score : 10.7, n_buffer : 2337,eps = 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1638931/1159536909.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(s_list, dtype=torch.float), torch.tensor(a_list), \\\n",
      "/tmp/ipykernel_1638931/1159536909.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(r_prime_list), torch.tensor(s_prime_list, dtype=torch.float),torch.tensor(done_mask_lst)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :300, score : 10.9, n_buffer : 3527,eps = 0.065\n",
      "best score :  24\n",
      "best score :  27\n",
      "n_episode :400, score : 12.1, n_buffer : 4833,eps = 0.06\n",
      "best score :  29\n",
      "best score :  32\n",
      "n_episode :500, score : 12.2, n_buffer : 6152,eps = 0.055\n",
      "best score :  37\n",
      "n_episode :600, score : 11.5, n_buffer : 7405,eps = 0.05\n",
      "best score :  38\n",
      "n_episode :700, score : 13.8, n_buffer : 8884,eps = 0.045\n",
      "n_episode :800, score : 13.3, n_buffer : 10317,eps = 0.04\n",
      "n_episode :900, score : 13.6, n_buffer : 11780,eps = 0.035\n",
      "n_episode :1000, score : 13.7, n_buffer : 13251,eps = 0.03\n",
      "best score :  39\n",
      "n_episode :1100, score : 13.7, n_buffer : 14723,eps = 0.025\n",
      "best score :  41\n",
      "n_episode :1200, score : 15.3, n_buffer : 16350,eps = 0.020000000000000004\n",
      "best score :  50\n",
      "n_episode :1300, score : 14.8, n_buffer : 17926,eps = 0.015\n",
      "n_episode :1400, score : 15.4, n_buffer : 19570,eps = 0.009999999999999995\n",
      "n_episode :1500, score : 15.8, n_buffer : 21255,eps = 0.0050000000000000044\n",
      "best score :  88\n",
      "n_episode :1600, score : 18.2, n_buffer : 23176,eps = 0.0\n",
      "n_episode :1700, score : 18.8, n_buffer : 25157,eps = 0.0\n",
      "n_episode :1800, score : 18.0, n_buffer : 27053,eps = 0.0\n",
      "n_episode :1900, score : 17.6, n_buffer : 28917,eps = 0.0\n",
      "n_episode :2000, score : 17.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2100, score : 19.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2200, score : 19.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2300, score : 18.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2400, score : 18.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2500, score : 19.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2600, score : 17.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2700, score : 18.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2800, score : 21.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :2900, score : 19.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3000, score : 21.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3100, score : 22.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3200, score : 23.3, n_buffer : 30000,eps = 0.0\n",
      "best score :  95\n",
      "n_episode :3300, score : 23.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3400, score : 23.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3500, score : 22.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3600, score : 23.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3700, score : 24.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :3800, score : 24.5, n_buffer : 30000,eps = 0.0\n",
      "best score :  98\n",
      "best score :  107\n",
      "n_episode :3900, score : 29.9, n_buffer : 30000,eps = 0.0\n",
      "best score :  118\n",
      "n_episode :4000, score : 27.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :4100, score : 29.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :4200, score : 29.6, n_buffer : 30000,eps = 0.0\n",
      "best score :  134\n",
      "n_episode :4300, score : 32.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :4400, score : 35.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :4500, score : 33.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :4600, score : 39.0, n_buffer : 30000,eps = 0.0\n",
      "best score :  150\n",
      "n_episode :4700, score : 42.2, n_buffer : 30000,eps = 0.0\n",
      "best score :  176\n",
      "n_episode :4800, score : 43.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :4900, score : 38.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5000, score : 44.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5100, score : 52.1, n_buffer : 30000,eps = 0.0\n",
      "best score :  181\n",
      "best score :  370\n",
      "n_episode :5200, score : 49.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5300, score : 51.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5400, score : 51.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5500, score : 51.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5600, score : 52.4, n_buffer : 30000,eps = 0.0\n",
      "best score :  430\n",
      "n_episode :5700, score : 65.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5800, score : 66.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :5900, score : 52.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6000, score : 62.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6100, score : 70.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6200, score : 66.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6300, score : 66.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6400, score : 86.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6500, score : 67.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6600, score : 69.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6700, score : 74.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6800, score : 68.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :6900, score : 75.3, n_buffer : 30000,eps = 0.0\n",
      "best score :  491\n",
      "n_episode :7000, score : 83.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7100, score : 76.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7200, score : 77.1, n_buffer : 30000,eps = 0.0\n",
      "best score :  665\n",
      "n_episode :7300, score : 98.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7400, score : 80.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7500, score : 85.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7600, score : 74.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7700, score : 81.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7800, score : 74.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :7900, score : 86.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8000, score : 79.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8100, score : 94.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8200, score : 68.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8300, score : 94.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8400, score : 82.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8500, score : 90.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8600, score : 91.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8700, score : 67.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8800, score : 74.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :8900, score : 76.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9000, score : 91.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9100, score : 79.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9200, score : 79.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9300, score : 105.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9400, score : 95.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9500, score : 93.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9600, score : 59.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9700, score : 111.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9800, score : 86.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :9900, score : 88.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10000, score : 87.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10100, score : 108.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10200, score : 95.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10300, score : 83.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10400, score : 94.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10500, score : 93.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10600, score : 95.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10700, score : 96.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10800, score : 92.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :10900, score : 116.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11000, score : 106.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11100, score : 84.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11200, score : 82.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11300, score : 92.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11400, score : 76.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11500, score : 101.7, n_buffer : 30000,eps = 0.0\n",
      "best score :  742\n",
      "n_episode :11600, score : 87.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11700, score : 94.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11800, score : 105.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :11900, score : 97.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12000, score : 123.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12100, score : 115.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12200, score : 88.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12300, score : 102.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12400, score : 104.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12500, score : 104.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12600, score : 98.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12700, score : 99.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12800, score : 83.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :12900, score : 90.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13000, score : 91.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13100, score : 98.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13200, score : 124.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13300, score : 100.2, n_buffer : 30000,eps = 0.0\n",
      "best score :  767\n",
      "n_episode :13400, score : 121.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13500, score : 111.6, n_buffer : 30000,eps = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :13600, score : 113.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13700, score : 74.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13800, score : 83.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :13900, score : 102.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14000, score : 108.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14100, score : 126.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14200, score : 125.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14300, score : 105.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14400, score : 97.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14500, score : 96.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14600, score : 130.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14700, score : 105.5, n_buffer : 30000,eps = 0.0\n",
      "best score :  1080\n",
      "n_episode :14800, score : 141.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :14900, score : 123.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15000, score : 119.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15100, score : 107.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15200, score : 86.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15300, score : 107.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15400, score : 98.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15500, score : 99.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15600, score : 108.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15700, score : 96.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15800, score : 107.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :15900, score : 116.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16000, score : 134.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16100, score : 122.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16200, score : 113.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16300, score : 88.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16400, score : 96.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16500, score : 114.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16600, score : 134.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16700, score : 127.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16800, score : 107.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :16900, score : 117.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17000, score : 101.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17100, score : 118.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17200, score : 113.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17300, score : 124.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17400, score : 128.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17500, score : 117.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17600, score : 147.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17700, score : 94.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :17800, score : 141.0, n_buffer : 30000,eps = 0.0\n",
      "best score :  1578\n",
      "n_episode :17900, score : 160.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18000, score : 142.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18100, score : 132.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18200, score : 125.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18300, score : 114.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18400, score : 129.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18500, score : 119.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18600, score : 117.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18700, score : 153.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18800, score : 111.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :18900, score : 86.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19000, score : 99.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19100, score : 145.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19200, score : 98.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19300, score : 86.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19400, score : 139.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19500, score : 150.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19600, score : 116.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19700, score : 128.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19800, score : 126.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :19900, score : 131.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20000, score : 119.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20100, score : 138.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20200, score : 119.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20300, score : 138.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20400, score : 150.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20500, score : 115.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20600, score : 124.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20700, score : 155.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20800, score : 161.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :20900, score : 151.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21000, score : 151.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21100, score : 130.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21200, score : 150.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21300, score : 137.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21400, score : 143.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21500, score : 128.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21600, score : 155.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21700, score : 111.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21800, score : 120.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :21900, score : 140.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22000, score : 146.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22100, score : 139.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22200, score : 143.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22300, score : 112.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22400, score : 125.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22500, score : 168.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22600, score : 161.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22700, score : 163.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22800, score : 154.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :22900, score : 137.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23000, score : 123.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23100, score : 128.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23200, score : 145.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23300, score : 107.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23400, score : 90.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23500, score : 106.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23600, score : 155.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23700, score : 146.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23800, score : 151.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :23900, score : 174.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24000, score : 149.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24100, score : 127.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24200, score : 145.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24300, score : 161.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24400, score : 132.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24500, score : 150.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24600, score : 134.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24700, score : 131.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24800, score : 149.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :24900, score : 137.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25000, score : 141.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25100, score : 149.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25200, score : 135.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25300, score : 137.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25400, score : 140.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25500, score : 119.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25600, score : 115.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25700, score : 126.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25800, score : 124.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :25900, score : 136.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26000, score : 152.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26100, score : 139.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26200, score : 108.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26300, score : 145.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26400, score : 122.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26500, score : 105.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26600, score : 134.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26700, score : 142.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26800, score : 133.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :26900, score : 154.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27000, score : 131.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27100, score : 106.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27200, score : 86.2, n_buffer : 30000,eps = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :27300, score : 95.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27400, score : 120.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27500, score : 139.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27600, score : 156.0, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27700, score : 101.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27800, score : 127.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :27900, score : 143.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28000, score : 147.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28100, score : 129.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28200, score : 136.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28300, score : 127.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28400, score : 147.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28500, score : 128.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28600, score : 159.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28700, score : 120.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28800, score : 150.4, n_buffer : 30000,eps = 0.0\n",
      "n_episode :28900, score : 211.9, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29000, score : 152.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29100, score : 150.5, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29200, score : 150.7, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29300, score : 140.2, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29400, score : 139.3, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29500, score : 128.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29600, score : 142.1, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29700, score : 145.8, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29800, score : 160.6, n_buffer : 30000,eps = 0.0\n",
      "n_episode :29900, score : 143.4, n_buffer : 30000,eps = 0.0\n"
     ]
    }
   ],
   "source": [
    "env = enva()\n",
    "q = Agent()\n",
    "q_target = Agent()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "memory = replay_buffer()  \n",
    "q.load_state_dict(torch.load('DQN_ddong_with_dongmin.pt'))\n",
    "optimizer = optim.Adam(q.parameters(),lr = 0.0005)\n",
    "score = 0.0\n",
    "best_score = 0.\n",
    "\n",
    "for epi in range(30000):\n",
    "\n",
    "    eps = max(0.0, 0.08 - 0.01*(epi/200)) #0,08\n",
    "    s = env.reset()\n",
    "   \n",
    "    done = False\n",
    "    one_score = 0\n",
    "    while not done :\n",
    "   \n",
    "        a = q.select_action(s.float(),eps)\n",
    "        s_prime,r,done,info = env.step(a)\n",
    "        done_mask = 0.0 if done else 1.0  # termination이면 done을 0으로..\n",
    "        memory.put((s,a,r,s_prime, done_mask)) # state, action, reward, state', done_mask\n",
    "        s = copy.deepcopy(s_prime)\n",
    "        score += r\n",
    "        one_score += r\n",
    "    if one_score > best_score:\n",
    "        best_score = one_score\n",
    "        print(\"...save model...\")\n",
    "        torch.save(q.state_dict(),\"DQN_ddong_with_dongmin.pt\")\n",
    "        print(\"best score : \",best_score)\n",
    "    if memory.size() >3000 :\n",
    "        train(q,q_target,memory,optimizer)\n",
    "\n",
    "    if epi%100==0 and epi!=0:\n",
    "        q_target.load_state_dict(q.state_dict())\n",
    "        print(\"n_episode :{}, score : {:.1f}, n_buffer : {},eps = {}\".format(\n",
    "                                                        epi, score/100, memory.size(),eps))\n",
    "        \n",
    "        score = 0.0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import random\n",
    "import keyboard\n",
    "import copy\n",
    "\n",
    "height = 10\n",
    "width = 10\n",
    "num_obstacle_range =7\n",
    "num_obstacle_range_min = 4\n",
    "turn = 0\n",
    "position = round(width/2)\n",
    "player_position = round(width/2)\n",
    "map = np.array([[0. for j in range(width)] for i in range(height)])\n",
    "map[height-1][position] = 2.\n",
    "\n",
    "player_map = copy.deepcopy(map)\n",
    "q.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    while True:\n",
    "        #print_map\n",
    "        action = q.forward(torch.flatten(torch.tensor(map).float()))\n",
    "        print(\"===============ai map==================\")\n",
    "        print(map)\n",
    "        print(\"===============player map==================\")\n",
    "        print(player_map)\n",
    "        print(\"Turn:\" ,turn)\n",
    "        #obstacle down\n",
    "        i = height - 2\n",
    "        while(i>=0):\n",
    "            map[i+1] = map[i]\n",
    "            i -= 1\n",
    "        #obstacle init(first_line)\n",
    "        map[0] = np.array([0. for j in range(width)])\n",
    "        #obstacle making\n",
    "        num_obstacle = random.randrange(num_obstacle_range_min,num_obstacle_range)\n",
    "        i = 0\n",
    "        while(i < num_obstacle):\n",
    "            position_obstacle = random.randrange(0,width)\n",
    "            if (map[0][position_obstacle] == 1.):\n",
    "                continue\n",
    "            map[0][position_obstacle] = 1.\n",
    "            i += 1\n",
    "        #big_obstacle\n",
    "        big_obstacle = random.randrange(0,20)\n",
    "        if(big_obstacle == 0):\n",
    "            big_obstacle = random.randrange(1,width-1)\n",
    "            for j in range(3):\n",
    "                for k in range(-1,2):\n",
    "                    map[j][big_obstacle + k] = 1.\n",
    "        #copy player_map\n",
    "        player_map = copy.deepcopy(map)\n",
    "        #ai position\n",
    "        #print(\"value : \",action)\n",
    "        action = torch.argmax(action).item()\n",
    "        #print(\"action : \", action)\n",
    "        \n",
    "        while True:\n",
    "            player_key = input()\n",
    "            key = action\n",
    "            # player action\n",
    "            if player_key == \"j\":\n",
    "                if(player_position>0):\n",
    "                    player_position -= 1\n",
    "                \n",
    "            if player_key == \"k\":\n",
    "                pass        \n",
    "            if player_key == \"l\":\n",
    "                if(player_position<width-1):\n",
    "                    player_position += 1\n",
    "                        \n",
    "\n",
    "            # ai action\n",
    "            if key == 0:\n",
    "                if(position>0):\n",
    "                    position -= 1\n",
    "                break\n",
    "            if key == 1:\n",
    "                break        \n",
    "            if key ==2:\n",
    "                if(position<width-1):\n",
    "                    position += 1\n",
    "                break        \n",
    "        if map[height-1][position] == 1 or player_map[height-1][player_position] == 1:\n",
    "                    print(\"====Game Over====\")\n",
    "                    if map[height-1][position] == 1:\n",
    "                        print(\"player win!!\\n\\n\")\n",
    "                    \n",
    "                    elif player_map[height-1][player_position] == 1:\n",
    "                        print(\"AI win!!\\n\\n\")\n",
    "                    sys.exit()    \n",
    "        map[height-1][position] = 2.\n",
    "        player_map[height-1][player_position] = 2.\n",
    "        #reward(turn(time))\n",
    "        turn += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d0c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1b463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
